name: Deploy to Azure Kubernetes Service

on:
  workflow_dispatch:
    inputs:
      backend_tag:
        description: "Backend image tag to deploy (e.g., v1.0.0, latest)"
        required: true
        default: "latest"
      frontend_tag:
        description: "Frontend image tag to deploy (e.g., v1.0.0, latest)"
        required: true
        default: "latest"

env:
  ACR_LOGIN_SERVER: ${{ vars.ACR_LOGIN_SERVER }}
  CLUSTER_NAME:     ${{ vars.CLUSTER_NAME }}
  RESOURCE_GROUP:   ${{ vars.RESOURCE_GROUP }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ env.RESOURCE_GROUP }} \
            --name ${{ env.CLUSTER_NAME }} \
            --overwrite-existing

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.0"

      - name: Install cert-manager (if needed)
        run: |
          kubectl get crd clusterissuers.cert-manager.io || \
          helm repo add jetstack https://charts.jetstack.io && \
          helm repo update && \
          helm install cert-manager jetstack/cert-manager \
            --namespace cert-manager \
            --create-namespace \
            --version v1.13.3 \
            --set installCRDs=true

          # Wait for cert-manager to be ready
          echo "Waiting for cert-manager to be ready..."
          
          kubectl rollout status deployment/cert-manager -n cert-manager --timeout=120s
          kubectl rollout status deployment/cert-manager-webhook -n cert-manager --timeout=120s
          kubectl rollout status deployment/cert-manager-cainjector -n cert-manager --timeout=120s

          # Wait for the cert-manager ClusterIssuer CRD to exist (max 60s)
          echo "Waiting for cert-manager CRDs to be created..."
          for i in {1..12}; do
            if kubectl get crd clusterissuers.cert-manager.io > /dev/null 2>&1; then
              echo "clusterissuers.cert-manager.io CRD is present."
              break
            fi
            echo "Waiting for clusterissuers.cert-manager.io CRD to be created... ($i/12)"
            sleep 5
          done

          # Verify CRD exists before proceeding
          if ! kubectl get crd clusterissuers.cert-manager.io > /dev/null 2>&1; then
            echo "❌ Timed out waiting for clusterissuers.cert-manager.io CRD."
            exit 1
          fi

          # Wait a bit more for webhooks to be fully ready
          echo "Waiting for cert-manager webhooks to be fully ready..."
          sleep 10

      - name: Install NGINX Ingress Controller
        run: |
          kubectl get namespace ingress-nginx || \
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx && \
          helm repo update && \
          helm install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.service.loadBalancerIP="${{ vars.INGRESS_IP }}" \
            --set controller.admissionWebhooks.enabled=true \
            --set controller.admissionWebhooks.patch.enabled=true
          kubectl rollout status deployment/ingress-nginx-controller -n ingress-nginx --timeout=120s
          
          # Wait for webhook to be ready
          echo "Waiting for nginx-ingress webhook to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=ingress-nginx -n ingress-nginx --timeout=120s
          
          # Additional wait for webhook service
          sleep 10

      - name: Install Keel
        run: |
          kubectl get namespace keel || \
          helm repo add keel https://charts.keel.sh && \
          helm repo update && \
          helm install keel keel/keel \
            --namespace keel \
            --create-namespace \
            --set helmProvider.enabled="true" \
            --set helmProvider.pollInterval="1m" \
            --set basicAuth.enabled="true" \
            --set basicAuth.username="${{ secrets.ADMIN_USER }}" \
            --set basicAuth.password="${{ secrets.ADMIN_PASS }}"
          kubectl rollout status deployment/keel -n keel --timeout=120s

      - name: Ensure namespace exists
        run: |
          kubectl get namespace campus-connect || kubectl create namespace campus-connect

      - name: Deploy Shared Resources
        run: |
          # Wait for nginx-ingress to be fully ready before applying ingress resources
          echo "Ensuring nginx-ingress is fully ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=ingress-nginx -n ingress-nginx --timeout=180s
          
          # Wait for cert-manager webhook to be ready
          echo "Ensuring cert-manager webhook is ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=cert-manager -n cert-manager --timeout=180s
          
          # Disable problematic webhooks temporarily
          echo "Temporarily disabling webhooks to avoid HTTPS/HTTP issues..."
          kubectl delete validatingwebhookconfiguration ingress-nginx-admission 2>/dev/null || true
          kubectl delete mutatingwebhookconfiguration cert-manager-webhook 2>/dev/null || true
          kubectl delete validatingwebhookconfiguration cert-manager-webhook 2>/dev/null || true
          
          # Wait a moment for webhook deletion to propagate
          sleep 10
          
          # Deploy shared resources without webhook interference
          echo "Deploying shared resources..."
          helm upgrade --install shared ./helm/shared \
            --set letsencrypt.email="${{ vars.LETSENCRYPT_EMAIL }}" \
            --set domain="${{ vars.DOMAIN }}"
          
          # Re-enable webhooks after deployment
          echo "Re-enabling webhooks..."
          kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml 2>/dev/null || true
          
          # Wait for webhooks to be ready again
          sleep 15

      - name: Set Tags
        run: |
          echo "BACKEND_TAG=${{ github.event.inputs.backend_tag }}" >> $GITHUB_ENV
          echo "FRONTEND_TAG=${{ github.event.inputs.frontend_tag }}" >> $GITHUB_ENV
          echo "Deploying backend with tag: ${{ github.event.inputs.backend_tag }}"
          echo "Deploying frontend with tag: ${{ github.event.inputs.frontend_tag }}"

      - name: Deploy Backend
        run: |
          MONGO_HOST="campusconnect-prod.rzyiqr0.mongodb.net"
          MONGO_PORT="27017"
          MONGO_DB="CampusConnect-Prod"
          echo "MongoDB config: Host=$MONGO_HOST, Port=$MONGO_PORT, DB=$MONGO_DB"
          echo "Deploying backend with tag: ${{ env.BACKEND_TAG }}"
          helm upgrade --install backend ./helm/backend \
            --namespace campus-connect --create-namespace \
            --set image.repository="${{ env.ACR_LOGIN_SERVER }}/${{ vars.BACKEND_IMAGE_NAME }}" \
            --set image.tag="${{ env.BACKEND_TAG }}" \

            --set domain="${{ vars.DOMAIN }}" \
            --set mongodb.host="$MONGO_HOST" \
            --set mongodb.port="$MONGO_PORT" \
            --set mongodb.database="$MONGO_DB" \
            --set config.nodeEnv="production" \
            --set config.host="0.0.0.0" \
            --set config.port="3000" \
            --set config.apiPrefix="/api" \
            --set config.sessionLifetime="86400000" \
            --set config.cookieSecure="true" \
            --set config.cookieSameSite="Strict" \
            --set config.corsOrigin="${{ vars.DOMAIN }}" \
            --set-string secrets.mongodb_uri="${{ secrets.MONGODB_URI }}" \
            --set-string secrets.encryption_key="${{ secrets.ENCRYPTION_KEY }}" \
            --set-string secrets.session_secret="${{ secrets.SESSION_SECRET }}" \
            --set-string secrets.jwt_secret="${{ secrets.JWT_SECRET }}"

      - name: Deploy Frontend
        run: |
          echo "Deploying frontend with tag: ${{ env.FRONTEND_TAG }}"
          helm upgrade --install frontend ./helm/frontend \
            --namespace campus-connect --create-namespace \
            --set image.repository="${{ env.ACR_LOGIN_SERVER }}/${{ vars.FRONTEND_IMAGE_NAME }}" \
            --set image.tag="${{ env.FRONTEND_TAG }}" \
            --set config.apiUrl="/api" \
            --set domain="${{ vars.DOMAIN }}"

      - name: Wait for rollout
        run: |
          kubectl rollout status deployment/campus-connect-backend  -n campus-connect --timeout=300s
          kubectl rollout status deployment/campus-connect-frontend -n campus-connect --timeout=300s

      - name: Wait for pods to be ready
        run: |
          kubectl wait pod -l app=campus-connect-backend  -n campus-connect --for=condition=ready --timeout=300s
          kubectl wait pod -l app=campus-connect-frontend -n campus-connect --for=condition=ready --timeout=300s

      - name: Check for crashed pods
        run: |
          set -e
          # Check backend
          BACKEND_READY=$(kubectl get pods -n campus-connect -l app=campus-connect-backend -o json | jq '[.items[] | select(.status.phase=="Running") | select(.status.containerStatuses[]?.ready==true)] | length')
          BACKEND_CRASHED=$(kubectl get pods -n campus-connect -l app=campus-connect-backend | grep -E 'CrashLoopBackOff|Error' || true)
          if [[ "$BACKEND_READY" -lt 1 ]]; then
            echo "❌ No running and ready backend pods found!"
            kubectl get pods -n campus-connect -l app=campus-connect-backend
            exit 1
          fi
          if [[ -n "$BACKEND_CRASHED" ]]; then
            echo "⚠️ Warning: Some backend pods are in a crashed state:"
            echo "$BACKEND_CRASHED"
          fi
          # Check frontend
          FRONTEND_READY=$(kubectl get pods -n campus-connect -l app=campus-connect-frontend -o json | jq '[.items[] | select(.status.phase=="Running") | select(.status.containerStatuses[]?.ready==true)] | length')
          FRONTEND_CRASHED=$(kubectl get pods -n campus-connect -l app=campus-connect-frontend | grep -E 'CrashLoopBackOff|Error' || true)
          if [[ "$FRONTEND_READY" -lt 1 ]]; then
            echo "❌ No running and ready frontend pods found!"
            kubectl get pods -n campus-connect -l app=campus-connect-frontend
            exit 1
          fi
          if [[ -n "$FRONTEND_CRASHED" ]]; then
            echo "⚠️ Warning: Some frontend pods are in a crashed state:"
            echo "$FRONTEND_CRASHED"
          fi

      - name: Test application endpoints
        run: |
          set -euo pipefail
          echo "=== Testing application health ==="

          # Wait up to 5 minutes for Ingress IP
          for i in {1..30}; do
            INGRESS_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller \
              -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [[ -n "$INGRESS_IP" ]]; then
              echo "Ingress IP: $INGRESS_IP"
              break
            fi
            echo "Waiting for Ingress IP ($i/30)…"
            sleep 10
          done
          if [[ -z "${INGRESS_IP:-}" ]]; then
            echo "❌ Ingress IP not available"
            exit 1
          fi

          # Poll health endpoints
          for i in {1..30}; do
            FRONTEND_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "http://$INGRESS_IP/")
            BACKEND_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "http://$INGRESS_IP/api/health")
            if [[ "$FRONTEND_STATUS" == "200" && "$BACKEND_STATUS" == "200" ]]; then
              echo "✅ Application health checks passed!"
              exit 0
            fi
            echo "Health not ready: frontend=$FRONTEND_STATUS backend=$BACKEND_STATUS ($i/30)"
            sleep 10
          done

          echo "❌ Application health checks failed after waiting"
          exit 1
